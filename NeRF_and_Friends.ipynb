{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeRF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOAV4CyHCwNH32AkGeazLZ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daia99/nerf_pl/blob/master/NeRF_and_Friends.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6Op-41hHDZE"
      },
      "source": [
        "# Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frggRrHaFzQO"
      },
      "source": [
        "This notebook is able to run COLMAP for image pose estimation, NeRF (Lightning implementation), NeX-MPI, and NeRF-SH/PlenOctree extraction. \n",
        "\n",
        "Forks of NeRF, and PlenOctree test out improvements to initial training stability implemented in: https://github.com/google/mipnerf\n",
        "\n",
        "Forks also contain calls os.system('rsync -r...') to save checkpoints somewhere in Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLS34UPJGcFM"
      },
      "source": [
        "# Sources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U9rnJPVEBWG"
      },
      "source": [
        "- https://gist.github.com/kwea123/f0e8f38ff2aa94495dbfe7ae9219f75c (COLMAP in Colab)\n",
        "- https://gist.github.com/kwea123/a3c541a325e895ef79ecbc0d2e6d7221 (NeRF PyTorch Lightning implementation)\n",
        "- https://github.com/nex-mpi/nex-code/ (NeX-MPI source and Colab notebook)\n",
        "- https://github.com/sxyu/plenoctree (PlenOctree source)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJYj0n-YGS8M"
      },
      "source": [
        "# Misc Utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecytJK18AtJ6"
      },
      "source": [
        "Check GPU in current instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3emq7hI_AT-7"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYibNLKNFv8E"
      },
      "source": [
        "Use this in case debugging with remote access to Colab instance is desired (https://github.com/WassimBenzarti/colab-ssh)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC-HYxfpFxz6"
      },
      "source": [
        "# Install colab_ssh on google colab\n",
        "!pip install colab_ssh --upgrade\n",
        "\n",
        "from colab_ssh import launch_ssh_cloudflared, init_git_cloudflared\n",
        "launch_ssh_cloudflared(password=\"AnyPasswordHere\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yu_07ToAQj5"
      },
      "source": [
        "# Calculate Pose from Images\n",
        "Note: 12-30 images for forward-facing scenes, and 50-100 images for 360 scenes are recommended\n",
        "\n",
        "First, mount Google Drive to Colab to load data into workspace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYzJwURhAFrr"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkEWBmkSA4MJ"
      },
      "source": [
        "Install prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqNAjwJmA23G"
      },
      "source": [
        "!sudo apt-get install \\\n",
        "    git \\\n",
        "    cmake \\\n",
        "    build-essential \\\n",
        "    libboost-program-options-dev \\\n",
        "    libboost-filesystem-dev \\\n",
        "    libboost-graph-dev \\\n",
        "    libboost-regex-dev \\\n",
        "    libboost-system-dev \\\n",
        "    libboost-test-dev \\\n",
        "    libeigen3-dev \\\n",
        "    libsuitesparse-dev \\\n",
        "    libfreeimage-dev \\\n",
        "    libgoogle-glog-dev \\\n",
        "    libgflags-dev \\\n",
        "    libglew-dev \\\n",
        "    qtbase5-dev \\\n",
        "    libqt5opengl5-dev \\\n",
        "    libcgal-dev \\\n",
        "    libcgal-qt5-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGhIm39pEzeT"
      },
      "source": [
        "Install Ceres-solver (takes 10-20 mins)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq8FO12REyxD"
      },
      "source": [
        "%cd /content\n",
        "!sudo apt-get install libatlas-base-dev libsuitesparse-dev\n",
        "!git clone https://ceres-solver.googlesource.com/ceres-solver\n",
        "%cd ceres-solver\n",
        "!git checkout $(git describe --tags) # Checkout the latest release\n",
        "%mkdir build\n",
        "%cd build\n",
        "!cmake .. -DBUILD_TESTING=OFF -DBUILD_EXAMPLES=OFF\n",
        "!make\n",
        "!sudo make install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mIdEyAwFAvk"
      },
      "source": [
        "Install COLMAP (10-20 mins)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJHyL8QUE__p"
      },
      "source": [
        "!git clone https://github.com/colmap/colmap\n",
        "%cd colmap\n",
        "!git checkout dev\n",
        "%mkdir build\n",
        "%cd build\n",
        "!cmake ..\n",
        "!make\n",
        "!sudo make install\n",
        "!CC=/usr/bin/gcc-6 CXX=/usr/bin/g++-6 cmake .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWjPmFP5FJP6"
      },
      "source": [
        "Clone LLFF for utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm04lMJYFHo2"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/Fyusion/LLFF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i8a5Wj0FbUU"
      },
      "source": [
        "Run images to pose utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xqPYMpqFQlh"
      },
      "source": [
        "%cd /content/LLFF\n",
        "# change the path below to your data folder (the folder containing the `images` folder)\n",
        "!python imgs2poses.py \"/content/drive/My Drive/path/to/folder\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIlTJb9jO6Xl"
      },
      "source": [
        "# NeRF PL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_omFk09VO-3D"
      },
      "source": [
        "Install prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwVwcKXhPG5a"
      },
      "source": [
        "%cd /content\n",
        "!git clone --recursive https://github.com/daia99/nerf_pl # fork of https://github.com/kwea123/nerf_pl\n",
        "\n",
        "%cd /content/nerf_pl\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "%cd /content/nerf_pl/torchsearchsorted\n",
        "!pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te_xkFcUQBoE"
      },
      "source": [
        "Train your NeRF scene"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRTMuxfpPMl_"
      },
      "source": [
        "%cd /content/nerf_pl\n",
        "\n",
        "import os\n",
        "# set training configurations here\n",
        "os.environ['ROOT_DIR'] = \"/content/drive/My Drive/colab/nerf/nerf_llff_data/fern\"\n",
        "                         # directory containing the data\n",
        "os.environ['IMG_W'] = \"504\" # image width (do not set too large)\n",
        "os.environ['IMG_H'] = \"378\" # image height (do not set too large)\n",
        "os.environ['NUM_EPOCHS'] = \"30\" # number of epochs to train (depending on how many images there are,\n",
        "                                # 20~30 might be enough)\n",
        "os.environ['EXP'] = \"fern\" # name of the experience (arbitrary)\n",
        "os.environ['CKPT_PATH'] = '/content/drive/My Drive/ckpts/epoch=10.ckpt' # if you have PyTorch ckpt file saved to continue training\n",
        "\n",
        "# In case of limited memory, reduce batch_size, or use N_importance with 64\n",
        "# Default for forward-facing scenes using NDC. If training on 360 scenes, add flags --spheric and --use_disp\n",
        "!python train.py \\\n",
        "   --dataset_name llff \\\n",
        "   --root_dir \"$ROOT_DIR\" \\\n",
        "   --N_importance 128 --img_wh $IMG_W $IMG_H \\\n",
        "   --num_epochs $NUM_EPOCHS --batch_size 1024 \\\n",
        "   --optimizer adam --lr 5e-4 \\\n",
        "   --lr_scheduler cosine \\\n",
        "   --exp_name $EXP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcE0QUcTQEbq"
      },
      "source": [
        "Create rendering from your trained NeRF scene"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdK6Wmg1P_pX"
      },
      "source": [
        "os.environ['SCENE'] = 'flower'\n",
        "os.environ['CKPT_PATH'] = '/content/drive/My Drive/ckpts/epoch=10.ckpt'\n",
        "\n",
        "# spheric_poses flag for evaluating 360 scenes\n",
        "!python eval.py \\\n",
        "   --root_dir \"$ROOT_DIR\" \\\n",
        "   --dataset_name llff --scene_name $SCENE \\\n",
        "   --img_wh $IMG_W $IMG_H --N_importance 64 --ckpt_path $CKPT_PATH --spheric_poses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXZRitz-fa0u"
      },
      "source": [
        "# NeX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNlvBt3NLYcR"
      },
      "source": [
        "It works well for forward-facing scenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VApLTFvfc57"
      },
      "source": [
        "Install prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBGMzDuHfevr"
      },
      "source": [
        "%cd /content\n",
        "!pip install lpips\n",
        "!git clone https://github.com/nex-mpi/nex-code.git\n",
        "!mkdir -p /content/nex-code/data\n",
        "!mkdir -p /content/nex-code/runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq-MxBjWgRRD"
      },
      "source": [
        "Copy dataset scene to cloned repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQLScZ8sgPUh"
      },
      "source": [
        "!cp -r \"/content/drive/My Drive/...\" \"/content/nex-code/data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BouPPFRRf_2Q"
      },
      "source": [
        "Load Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXMf3vLBf9sk"
      },
      "source": [
        "%cd /content/nex-code\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1ALbWqpgCN_"
      },
      "source": [
        "Train NeX scene"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGUB0PdQfx3w"
      },
      "source": [
        "%cd /content/nex-code\n",
        "\n",
        "# tensorboard will update every 2 epochs (72 step)\n",
        "# scene leads to local copy of scene input, model_dir is arbitrary name location for checkpointing\n",
        "# decrease layers/sublayers in MPI if oom errors occur, or reduce ray batch size.\n",
        "%time !python train.py -scene data/Shiny -model_dir Shiny -epochs 80 -layers 12 -sublayers 6 -ray 8000 -tb_toc 50 -num_workers 2 -llff_width 400 -http -web_width 4096"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A4s_sODv7aJ"
      },
      "source": [
        "Play rendered video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3xo-g8qv5iW"
      },
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "# change <model_dir> to name in model_dir arg as above\n",
        "video_path = \"runs/video_output/<model_dir>/video.mp4\"\n",
        "mp4 = open(video_path, \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\" controls playsinline autoplay muted loop>\n",
        "</video>\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ63gf29wO0N"
      },
      "source": [
        "Upload real-time web renderer for viewing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02NRtSrGviTi"
      },
      "source": [
        "# upload file to nex-mpi backend 🦉\n",
        "# please don't hack our server. thank you 🙏\n",
        "import os, uuid\n",
        "from IPython.display import HTML\n",
        "import time\n",
        "\n",
        "if not os.path.isfile(\"/usr/bin/rclone\"):\n",
        "  get_ipython().system_raw(\"curl -s https://rclone.org/install.sh | sudo bash\")\n",
        "file_path = str(uuid.uuid4())\n",
        "get_ipython().system_raw(\"wget -O rclone.conf https://gist.githubusercontent.com/pureexe/8a0774c5e9994e3ead4fa1be555d43a5/raw/984a5e412b9ae2a182aabc8cfae7e69d64c9e3f3/rclone.conf\")\n",
        "# change <model_dir> to name in model_dir arg as above\n",
        "!rclone --config=rclone.conf copy \"runs/html/<model_dir>\" \"nex:$file_path\" --contimeout 60s --timeout 300s --retries 3 --low-level-retries 10 --fast-list --max-backlog 400000 --transfers 20 --checkers 40 --buffer-size 64M --drive-chunk-size 64M --disable copy --drive-acknowledge-abuse --drive-keep-revision-forever --drive-stop-on-upload-limit --drive-stop-on-download-limit --drive-skip-shortcuts --drive-use-trash=false -q\n",
        "\n",
        "time.sleep(10) # we have to wait backend to process files a bit\n",
        "webgl_url = \"https://nex-mpi.github.io/viewer/viewer.html?scene=https://nex.mpi.workers.dev/{}\".format(file_path)\n",
        "print(\"Real time demo: {}\".format(webgl_url))\n",
        "HTML(f\"\"\"\n",
        "<iframe height=450 width=700 src=\"{webgl_url}\" style=\"border:0px;padding-top:10px\"></iframe>\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC36qSA0gtlw"
      },
      "source": [
        "# PlenOctree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPIQ862Tgvsv"
      },
      "source": [
        "Install prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOcfUMCrg30t"
      },
      "source": [
        "%cd /content\n",
        "# fork of https://github.com/sxyu/plenoctree, contains plenoctree/nerf_sh/config/llff.yaml that can be edited to pass flags to Python scripts\n",
        "!git clone https://github.com/daia99/plenoctree.git \n",
        "%cd /content/plenoctree\n",
        "!pip install -r requirements.txt\n",
        "!pip install --upgrade jax jaxlib==0.1.65+cuda110 -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
        "!pip install PyYAML==5.4.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek2Tzxc_WMXg"
      },
      "source": [
        "Load scene data to project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXzfkRMVWLCF"
      },
      "source": [
        "!mkdir -p /content/plenoctree/data\n",
        "!cp -r \"/content/drive/My Drive/...\" \"/content/plenoctree/data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty_8v9maXeOs"
      },
      "source": [
        "Resize image to reduce memory usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xACaGnl8XRRs"
      },
      "source": [
        "import numpy as np\n",
        "import os, imageio\n",
        "\n",
        "# original from https://github.com/Fyusion/LLFF/blob/master/llff/poses/pose_utils.py\n",
        "def _minify(basedir, factors=[], resolutions=[]):\n",
        "    needtoload = False\n",
        "    for r in factors:\n",
        "        imgdir = os.path.join(basedir, 'images_{}'.format(r))\n",
        "        if not os.path.exists(imgdir):\n",
        "            needtoload = True\n",
        "    for r in resolutions:\n",
        "        imgdir = os.path.join(basedir, 'images_{}x{}'.format(r[1], r[0]))\n",
        "        if not os.path.exists(imgdir):\n",
        "            needtoload = True\n",
        "    if not needtoload:\n",
        "        return\n",
        "    \n",
        "    from shutil import copy\n",
        "    from subprocess import check_output\n",
        "    \n",
        "    imgdir = os.path.join(basedir, 'images')\n",
        "    imgs = [os.path.join(imgdir, f) for f in sorted(os.listdir(imgdir))]\n",
        "    imgs = [f for f in imgs if any([f.endswith(ex) for ex in ['JPG', 'jpg', 'png', 'jpeg', 'PNG']])]\n",
        "    imgdir_orig = imgdir\n",
        "    \n",
        "    wd = os.getcwd()\n",
        "\n",
        "    for r in factors + resolutions:\n",
        "        if isinstance(r, int):\n",
        "            name = 'images_{}'.format(r)\n",
        "            resizearg = '{}%'.format(100./r)\n",
        "        else:\n",
        "            name = 'images_{}x{}'.format(r[1], r[0])\n",
        "            resizearg = '{}x{}'.format(r[1], r[0])\n",
        "        imgdir = os.path.join(basedir, name)\n",
        "        if os.path.exists(imgdir):\n",
        "            continue\n",
        "            \n",
        "        print('Minifying', r, basedir)\n",
        "        \n",
        "        os.makedirs(imgdir)\n",
        "        check_output('cp {}/* {}'.format(imgdir_orig, imgdir), shell=True)\n",
        "        \n",
        "        ext = imgs[0].split('.')[-1]\n",
        "        args = ' '.join(['mogrify', '-resize', resizearg, '-format', 'png', '*.{}'.format(ext)])\n",
        "        print(args)\n",
        "        os.chdir(imgdir)\n",
        "        check_output(args, shell=True)\n",
        "        os.chdir(wd)\n",
        "        \n",
        "        if ext != 'png':\n",
        "            check_output('rm {}/*.{}'.format(imgdir, ext), shell=True)\n",
        "            print('Removed duplicates')\n",
        "        print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DxmjzkYXjs0"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install imagemagick"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tre3NnsgwcSp"
      },
      "source": [
        "Scale down images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fogdq4rfXm5J"
      },
      "source": [
        "%cd /content\n",
        "scene_dir = \"/content/plenoctree/data/lego\" # to directory of scene in project\n",
        "\n",
        "scale_factors = [4, 6] # input list of dim factors for each desired set of shrunken images\n",
        "_minify(scene_dir, factors = scale_factors) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyatfGjDWiaC"
      },
      "source": [
        "Train NeRF-SH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VocrdgetXCgN"
      },
      "source": [
        "%cd /content/plenoctree\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ckpt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU8l6IhZWelp"
      },
      "source": [
        "%cd /content/plenoctree\n",
        "!export DATA_ROOT=./data/NeRF/nerf_synthetic/\n",
        "!export CKPT_ROOT=./data/Plenoctree/checkpoints/syn_sh16/\n",
        "!export SCENE=chair\n",
        "!export CONFIG_FILE=nerf_sh/config/blender\n",
        "\n",
        "# read: https://jax.readthedocs.io/en/latest/gpu_memory_allocation.html\n",
        "os.environ['XLA_PYTHON_CLIENT_ALLOCATOR'] = 'default' # platform (lower GPU memory usage) or default\n",
        "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'true'\n",
        "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '.5' # reduce if crashes due to low RAM\n",
        "\n",
        "# for llff spherical scenes, extraction after lindisp arg training is not supported, so this is set to false (leading to reduced initial training stability)\n",
        "!python -m nerf_sh.train \\\n",
        "    --train_dir $CKPT_ROOT/$SCENE/ \\\n",
        "    --config $CONFIG_FILE \\\n",
        "    --data_dir $DATA_ROOT/$SCENE/\n",
        "\n",
        "!python -m nerf_sh.eval \\\n",
        "    --chunk 4096 \\\n",
        "    --train_dir $CKPT_ROOT/$SCENE/ \\\n",
        "    --config $CONFIG_FILE \\\n",
        "    --data_dir $DATA_ROOT/$SCENE/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDlpUbxbYBeU"
      },
      "source": [
        "Convert NeRF-SH model to PlenOctree and optimize. Possible to evaluate and compress the PlenOctree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhZtotldYAac"
      },
      "source": [
        "%cd /content/plenoctree\n",
        "import os\n",
        "\n",
        "!export DATA_ROOT=./data/NeRF/nerf_synthetic/\n",
        "!export CKPT_ROOT=./data/Plenoctree/checkpoints/syn_sh16\n",
        "!export SCENE=chair\n",
        "!export CONFIG_FILE=nerf_sh/config/blender\n",
        "\n",
        "# in config file, you can add arguments (reduce radius and increase bbox_scale to ensure extracted PlenOctree can load on their volrend tool)\n",
        "!python -m octree.extraction \\\n",
        "    --train_dir $CKPT_ROOT/$SCENE/ --is_jaxnerf_ckpt \\\n",
        "    --config $CONFIG_FILE \\\n",
        "    --data_dir $DATA_ROOT/$SCENE/ \\\n",
        "    --output $CKPT_ROOT/$SCENE/octrees/tree.npz\n",
        "\n",
        "!python -m octree.optimization \\\n",
        "    --input $CKPT_ROOT/$SCENE/tree.npz \\\n",
        "    --config $CONFIG_FILE \\\n",
        "    --data_dir $DATA_ROOT/$SCENE/ \\\n",
        "    --output $CKPT_ROOT/$SCENE/octrees/tree_opt.npz\n",
        "\n",
        "!python -m octree.evaluation \\\n",
        "    --input $CKPT_ROOT/$SCENE/octrees/tree_opt.npz \\\n",
        "    --config $CONFIG_FILE \\\n",
        "    --data_dir $DATA_ROOT/$SCENE/\n",
        "\n",
        "# [Optional] Only used for in-browser viewing.\n",
        "!python -m octree.compression \\\n",
        "    $CKPT_ROOT/$SCENE/octrees/tree_opt.npz \\\n",
        "    --out_dir $CKPT_ROOT/$SCENE/ \\\n",
        "    --overwrite"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}